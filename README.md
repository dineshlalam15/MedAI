ğŸ“Œ RAG-Powered Document Chatbot using LangChain & OpenAI

ğŸ“ Description:
- This project implements a Retrieval-Augmented Generation (RAG) pipeline that allows users to upload documents (PDFs, text, or other formats) and interact with them via a conversational interface. It uses LangChain for orchestration, FAISS for vector storage, and OpenAI GPT models for natural language understanding.

âš¡ Features:
- ğŸ“‚ Document Ingestion: Upload and process multiple documents into embeddings.
- ğŸ” Efficient Retrieval: Uses FAISS vector store for semantic search.
- ğŸ’¬ Conversational Q&A: Ask context-aware questions based on your documents.
- âš™ Customizable Pipelines: Easily swap out models, embeddings, or vector DBs.
- ğŸ Python Based: Simple to run locally or deploy to the cloud.

ğŸ› ï¸ Tech Stack:
- Python 3.10+
- LangChain
- OpenAI GPT API
- FAISS Vector Store
- PyPDF2 / Unstructured / Chroma (optional)

ğŸ¢ Code Architecture:
MedAI/
â”‚
â”œâ”€â”€ app/                        # Main application code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Reads from .env
â”‚   â”œâ”€â”€ ingestion.py           # Fetch + preprocess medical data
â”‚   â”œâ”€â”€ embeddings.py          # Generate embeddings
â”‚   â”œâ”€â”€ vectorstore.py         # Store/retrieve embeddings
â”‚   â”œâ”€â”€ retrieval.py           # Query + retrieve passages
â”‚   â”œâ”€â”€ llm.py                 # LLM query & synthesis
â”‚   â”œâ”€â”€ ui.py                  # Streamlit/Flask UI
â”‚
â”œâ”€â”€ data/                      # Raw and processed data
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ retrieval_prompts.ini
â”‚   â”œâ”€â”€ summarization_prompts.ini
â”‚   â”œâ”€â”€ classification_prompts.ini
â”‚   â””â”€â”€ system_prompts.ini
|
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Pipfile
â”œâ”€â”€ Pipfile.lock
â”œâ”€â”€ README.md
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â””â”€â”€ .gitignore